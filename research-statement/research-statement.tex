\documentclass[11pt]{article}

\usepackage[english]{babel}

\usepackage[margin=0.8in, top=0.3in]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{iris}{HTML}{5D3FD3}

\hypersetup
{
   colorlinks=true,
  linkcolor=iris,
  urlcolor={iris},
  filecolor={iris},
  citecolor={iris},
  allcolors={iris}
}

\usepackage{natbib}
\renewcommand{\bibsection}{\subsubsection*{References}}
\setlength{\bibsep}{0pt plus 0.3ex}


\begin{document}

\begin{center}
\large \textsc{Research Statement of Marios Papachristou} \normalsize {(\today, \href{https://papachristoumarios.github.io}{\texttt{[webpage]}}, \href{mailto:papachristoumarios@cs.cornell.edu}{\texttt{[e-mail]}})} 
\end{center}

\medskip


My name is Marios Papachristou and I am a 2nd year Ph.D. student at Cornell University advised by \href{https://www.cs.cornell.edu/home/kleinber}{Jon Kleinberg}. Prior to that, I received my MEng from the \href{https://www.ece.ntua.gr/gr}{School of ECE at NTUA}, where I worked with \href{http://www.softlab.ntua.gr/~fotakis/}{Dimitris Fotakis}. In the past, I have also been affiliated with the BaLaB at AUEB, where I worked with \href{https://www2.dmst.aueb.gr/dds}{Diomidis Spinellis}. The main area of my research is \emph{data science} through the lens of \emph{network science}. I am particularly interested in how complex networks, such as social networks,  financial networks, software systems  of various disciplines interact. 


\noindent \textbf{Financial Contagion \& Stimulus Allocations.} The COVID-19 pandemic has spread uncertainty among financial entities who experience \emph{income shocks}. A policy framework is \emph{stimulus checks}, i.e. cash injections so that consumption is stimulated. A cardinal question faced by policymakers is: \emph{Who gets the subsidies?}. 
% In the US the CARES act \cite{act2020cares} gives a stimulus check within a certain range of income and increases the payments proportionally to the number of dependents. Other countries such as, for example, New Zealand\footnote{\url{https://www.theguardian.com/world/2020/mar/17/new-zealand-launches-massive-spending-package-to-combat-covid-19}} and Greece\footnote{\url{https://www.ekathimerini.com/economy/258852/measures-announced-for-relieving-lockdown-pressure-on-workers-households}} offer stimulus checks of fixed value to affected employees. 
A common pattern in these scenarios is that when somebody's income is below a certain threshold or satisfies some criterion then the household is entitled to a stimulus check of fixed value which can depend on the entity's features (e.g. number of dependents, income, disruption of business etc.). However, such rules are limited by ignoring \emph{contagion} effects through the financial network. For example, if a business defaults that may translate to job loss for the employees who in their turn may not be able to pay their rent etc. Our work in \cite{papachristou2021allocating} addresses this timely issue, namely we try to optimally allocate \emph{stimulus checks} to individuals who are subject to (i) shocks; (ii) financial contagion. We prove theoretical intractability results, and develop efficient algorithms that approximate the  optimal solutions. We also introduce fairness constraints regarding the allocation and study how fairly allocating stimuli affects the social welfare. 
Closing, we test our methods with real-world and semi-artificial data and compare them to heuristics that may represent na\"ive policies which are currently used by governments, such as bailing individuals and businesses who earn less than a threshold income.
Our work can spark interest on a variety of interdisciplinary directions: For instance, extending this work to account for \emph{temporal evolution} (see also \cite{abebe2020subsidy}) can give an even better model that accounts for many types of dependencies.
Moreover, another possible direction is to do more empirical studies of contagion using more finely-grained governmental data.

% The subject of who to bailout in a financial crisis is a subject of controversy~\cite{jihong2009save, congleton2009political, casey2015framework, brill2009sa, rosas2006bagehot, blau2013corporate, bechtel2017policy}, namely the policymakers are faced with the following quandary: do we need to bailout large businesses whose saving from default would help maintain job positions but can also make them richer and stronger with respect to the rest of the population, or do we need to bailout individuals (or groups thereof) and small businesses so as they are able to afford their rent and groceries with the fear of letting bigger companies collapse? 

\noindent \textbf{Core-Periphery Networks.} Today's social networks (SN) contain a massive amount of nodes, and many conventional network analysis algorithms and machine learning algorithms usually fail to scale in huge networks. Arguably, many network analysis tasks can be made considerably faster by taking advantage of sets of nodes that are important for the network. A very important subset of nodes in a network is its ``core'', that is a very small  subset of the nodes that cover almost everyone else on the network, with the rest of the network playing the role of the ``periphery''. In \cite{papachristou2021sublinear}, I have recently observed and theorized that the core of many real-world networks is in fact \emph{sublinear}, that is if the network has $n$ nodes, the core has size proportional to $n^c$ for $c \in (0, 1)$. The main concept behind exploiting the core--periphery structural property of networks to speed up computational tasks is based on the general idea that \emph{intense} computational tasks can be performed within the \emph{sublinear core} and then the results can be aggregated to the periphery with relatively low query complexity. We have successfully used this idea for inferring the features (e.g. interests, hobbies) of users on a large SN in \cite{papachristou2021stochastic} outperforming ML methods such as node embeddings.  So, leveraging the connection between dominating sets and the core--periphery structure from an algorithmic viewpoint is   a novel perspective on \emph{efficient algorithms on large SN} can be used in many problems such as all-pairs-shortest-paths computation, community detection, embedding generation, and many more. 




\nocite{*}

{\small
\bibliographystyle{plain}
\bibliography{references}
}


\end{document}